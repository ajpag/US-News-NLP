dat %>% filter(schoolid == 1) %>% select(res1) %>% summarise(mean(res1))
dta
library(foreign)
library(lme4)
library(lmerTest)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
# convert IDs to factor
cols_factor <- c("classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
length(unique(cl$ses))
hist(cl$ses)
cor(cl$ses, cl$mathkind)
cor(cl)
# unconditional means model
lme1 <- lmer(mathgain ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme1)
str(cl)
summary(lme1)
str(cl)
# unconditional means model
lme2 <- lmer(mathgain ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2)
summary(lme2)
?ranova
ranova(lme2)
lme3 <- lmer(mathgain ~  mathkind + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme3)
# model fit
summary(lme3)
length(unique(cl$mathkind))
length(unique(cl$classid))
length(unique(cl$schoolid))
hist(cl$schoolid)
hist(cl$mathkind)
cor(cl$mathkind, cl$mathgain)
plot(cl$mathkind, cl$mathgain)
lme4 <- lmer(mathgain ~ mathkind + ses + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme4)
summary(lme4)
?summary
tapply(cl$mathkind, index = 1, fun = mean)
tapply(cl$schoolid, $mathkind, cl$mathkind, fun = mean)
tapply(cl$schoolid, cl$mathkind, cl$mathkind, fun = mean)
tapply(cl$schoolid, cl$mathkind, mean)
tapply(cl$mathkind, cl$schoolid, mean)
boxplot(cl$mathkind)
boxplot(cl$mathkind, cl$schoolid)
boxplot(cl[ , c("mathkind", "schoolid")])
boxplot(cl[ , "schoolid"])
tapply(cl$schoolid, cl$mathkind, mean)
tapply(cl$mathkind, cl$schoolid, mean)
plot(tapply(cl$mathkind, cl$schoolid, mean))
plot(sort(tapply(cl$mathkind, cl$schoolid, mean)))
plot(sort(cl$mathkind))
plot(sort(tapply(cl$mathkind, cl$schoolid, mean)))
plot(sort(cl$mathkind))
library(dplyr)
# add variables
cl %>% group_by(schoolid) %>% summarise(ses_sch = mean(ses))
unique(cl$classid)
dim(cl)
ses_cls <- cl %>% group_by(schoolid, classid) %>% summarise(ses_cls = mean(ses))
dim(ses_cls)
head(ses_cls)
# add variables
ses_sch <- cl %>% group_by(schoolid) %>% summarise(ses_sch = mean(ses))
ses_cls <- cl %>% group_by(schoolid, classid) %>% summarise(ses_cls = mean(ses))
mk_sch <- cl %>% group_by(schoolid) %>% summarise(mk_sch = mean(mathkind))
mk_cls <- cl %>%
group_by(schoolid, classid) %>%
summarise(mk_cls = mean(mathkind))
dim(mk_cls)
head(mk_class)
head(mk_cls)
dim(cl)
?join
cl %>% inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
# add columns to main data
cl_new <- cl %>% inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
dim(cl_new)
colnames(cl_new)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl_new)
str(cl_new)
# log likelihood
logLik(lme5)
unique(cl$classid)
cl %>% group_by(schoolid, classid) %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% arrange(schoolid, classid) %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% arrange(schoolid, classid) %>% n()
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% select(classid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% select(classid) %>% dim
312/107
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct()
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n_distinct(classid))
cl %>% group_by(schoolid, classid) %>% summarise(class_per_sch = n(), class_n = n_distinct(classid))
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n())
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n(schoolid))
cl %>% group_by(schoolid, classid) %>% summarise(class_n = count(schoolid))
cl %>% group_by(schoolid, classid)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(count(schoolid))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(n))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% arrange(cnt)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% arrange(desc(cnt))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% mean
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% mean
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% summarise(mean)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% summarise(mean(cnt))
312 / 107
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% select(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt)
hist(cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt))
# model fit
summary(lme5)
summary(lme5)
lme2$
lme2
attributes(lme2)
lme2$class
lme2
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
# convert IDs to factor
cols_factor <- c("classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
# unconditional means model
lme1 <- lmer(mathgain ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme1)
summary(lme1)
lme2 <- lmer(mathgain ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2)
summary(lme2)
lme3 <- lmer(mathgain ~ mathkind + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme3)
# model fit
summary(lme3)
lme4 <- lmer(mathgain ~ mathkind + ses + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme4)
# model fit
summary(lme4)
# add variables
ses_sch <- cl %>% group_by(schoolid) %>% summarise(ses_sch = mean(ses))
ses_cls <- cl %>% group_by(schoolid, classid) %>% summarise(ses_cls = mean(ses))
mk_sch <- cl %>% group_by(schoolid) %>% summarise(mk_sch = mean(mathkind))
mk_cls <- cl %>%
group_by(schoolid, classid) %>%
summarise(mk_cls = mean(mathkind))
# add columns to main data
cl_new <- cl %>%
inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl_new)
# log likelihood
logLik(lme5)
# log likelihood
logLik(lme5)
# model fit
summary(lme5)
ls()
rm(list = ls())
ls()
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
dim(cl)
str(cl)
# convert IDs to factor
cols_factor <- c("classid", "schoolid", "childid")
cols_factor
unique(cl$sex)
unique(cl$minority)
# convert IDs to factor
cols_factor <- c("sex", "minority", "classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
str(cl)
cl["sex"]
# unconditional means model
lme1 <- lmer(mathkind ~ (1 | schoolid), data = cl)
lme1
summary(lme1)
# log likelihood
logLik(lme1)
summary(lme1)
lme2 <- lmer(mathkind ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2)
summary(lme2)
lme1a <- lmer(mathkind ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme1a)
summary(lme1a)
anova(lme1, lme1a)
?anova
anova(lme1, lme1a)
anova(lme1, lme1a, refit = False)
anova(lme1, lme1a, refit = FALSE)
anova(lme1, lme1a, refit = TRUE)
anova(lme1, lme1a, refit = FALSE)
str(cl)
# generate 1st grade math scores
cl$math1st <- cl$mathkind = cl$mathgain
# generate 1st grade math scores
cl$math1st <- cl$mathkind + cl$mathgain
head(cl)
# model
# unconditional means model
lme2 <- lmer(math1st ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme2)
lme2a <- lmer(math1st ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2a)
summary(lme2a)
anova(lme2, lme2a, refit = FALSE)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid / classid), data = cl)
logLik(lme3)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid / classid), data = cl)
logLik(lme3)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3)
summary(lme3)
lme3a <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3a)
summary(lme3a)
lme3b <- lmer(math1st ~ ses + sex + minority + (1 | schoolid / classid),
data = cl)
logLik(lme3b)
summary(lme3b)
anova(lme3a, lme3b)
anova(lme3a, lme3b, refit = FALSE)
lmer::anova
colnames(cl)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl)
logLik(lme4a)
summary(lme4a)
cl$yt_sq <- cl$yearstea^2
cl$yt_cyb <- cl$yearstea^3
head(cl)
head(cl, 20)
12.54^2
12.54^3
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
logLik(lme4d)
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
cl$yt_sq <- cl$yearstea^2
cl$yt_cub <- cl$yearstea^3
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
logLik(lme4d)
summary(lme4d)
anova(lme4a, lme4d)
anova(lme4a, lme4d, refit = FALSE)
hea(cl, 20)
head(cl, 20)
unique(cl$ses)
len(unique(cl$ses))
length(unique(cl$ses))
length(unique(cl$schoolid))
length(unique(cl$classid))
unique(cl$childid)
cl$classid
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
# convert to factor
cols_factor <- c("sex", "minority", "classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
# unconditional means model
lme1 <- lmer(mathkind ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme1)
summary(lme1)
lme1a <- lmer(mathkind ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme1a)
summary(lme1a)
anova(lme1, lme1a, refit = FALSE)
# generate 1st grade math scores
cl$math1st <- cl$mathkind + cl$mathgain
# model
# unconditional means model
lme2 <- lmer(math1st ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme2)
lme2a <- lmer(math1st ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2a)
summary(lme2a)
anova(lme2, lme2a, refit = FALSE)
lme3a <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3a)
summary(lme3a)
lme3b <- lmer(math1st ~ ses + sex + minority + (1 | schoolid / classid),
data = cl)
logLik(lme3b)
summary(lme3b)
anova(lme3a, lme3b, refit = FALSE)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl)
logLik(lme4a)
summary(lme4a)
cl$yt_sq <- cl$yearstea^2
cl$yt_cub <- cl$yearstea^3
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
logLik(lme4d)
summary(lme4d)
anova(lme4a, lme4d, refit = FALSE)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl, REML = FALSE)
logLik(lme4a)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl)
logLik(lme4a)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl, REML = FALSE)
logLik(lme4a)
```{r}
summary(lme4a)
cl$yt_sq <- cl$yearstea^2
cl$yt_cub <- cl$yearstea^3
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl,
REML = FALSE)
logLik(lme4d)
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
logLik(lme4d)
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl,
REML = FALSE)
logLik(lme4d)
summary(lme4d)
anova(lme4a, lme4d, refit = FALSE)
anova(lme4a, lme4d)
anova(lme4a, lme4d, refit = FALSE)
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
anova(lme1, lme1a, refit = TRUE)
anova(lme1, lme1a, refit = FALSE)
anova(lme2, lme2a, refit = TRUE)
anova(lme2, lme2a, refit = FALSE)
anova(lme3a, lme3b, refit = TRUE)
anova(lme3a, lme3b, refit = FALSE)
# not run
setwd("C:/Users/apagta950/Documents/NYU/Courses/Spring 2021/MDML/Final Project/US-News-NLP/analysis")
library(ggplot2)
library(dplyr)
library(lubridate)
library(readr)
library(reshape2)
library(tidyr)
library(tidytext)
# read cnn and reuters. Drop International Reuters news sources
articles <- bind_rows(read_csv("../data/news_data_cnn.csv"),
read_csv("../data/news_data_reuters.csv") %>%
filter(
(articles.source_domain == "www.reuters.com") &
(articles.source_name == "Reuters"))
)
articles %>%
group_by(articles.source_name) %>%
summarise(articles = n()) %>%
arrange(desc(articles))
tokenize_words <- function(df) {
# tokenize words and add sentiments given news dataframe
words <- df %>%
unnest_tokens(word, text) %>%
left_join(get_sentiments(lexicon = "bing") %>%
mutate(sentiment_bing = sentiment) %>%
select(-sentiment)) %>%
left_join(get_sentiments(lexicon = "afinn") %>%
mutate(sentiment_afinn = as.factor(value)) %>%
select(-value)) %>%
left_join(get_sentiments(lexicon = "loughran") %>%
mutate(sentiment_loughran = sentiment) %>%
select(-sentiment)) %>%
left_join(get_sentiments(lexicon = "nrc") %>%
mutate(sentiment_nrc = sentiment) %>%
select(-sentiment))
return(words)
}
# baseline: tokenize words
words <- tokenize_words(articles)
dim(words)
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_histogram(position = "dodge") +
labs(title = "Word Count Distribution")
words_long <- words %>%
pivot_longer(cols = contains("sentiment"),
names_to = "lexicon",
values_to = "sentiment")
words_long %>%
group_by(lexicon, sentiment, articles.source_name) %>%
drop_na() %>%
summarise(count = n()) %>%
group_by(lexicon, articles.source_name) %>%
mutate(pct_of_total = count / sum(count)) %>%
ggplot(aes(x = sentiment,
y = pct_of_total,
fill = articles.source_name)) +
geom_bar(stat = "identity", position = "dodge") +
facet_wrap(~lexicon, scales = "free") +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "bottom") +
labs(title = "Sentiment Distribution by Word")
words_long %>%
drop_na() %>%
mutate(date = floor_date(articles.published_datetime, unit = "week"),
sentiment = as.numeric(sentiment)) %>%
filter(lexicon == "sentiment_afinn") %>%
group_by(date, articles.source_name) %>%
summarise(avg_sentiment = mean(sentiment)) %>%
ggplot(aes(x = date, y = avg_sentiment, color = articles.source_name)) +
geom_line() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Average Sentiment by Week")
words %>%
group_by(word, articles.source_name) %>%
summarise(word_count = n()) %>%
group_by(articles.source_name) %>%
mutate(total_words = sum(word_count)) %>%
ggplot(aes(x = word_count / total_words)) +
geom_histogram() +
facet_wrap(~articles.source_name) +
labs(title = "Word Frequency Distribution", x = "pct of Words")
stop_words_custom <- tibble(word = c("n", "2w7hx9t"))
words_tf_idf <- words_long %>%
anti_join(stop_words_custom) %>%
group_by(word, articles.article_url, articles.source_name) %>%
summarise(word_count = n()) %>%
bind_tf_idf(word, articles.article_url, word_count)
words_tf_idf %>%
arrange(desc(tf_idf)) %>%
head(70) %>%
ggplot(aes(x = reorder(word, tf_idf),
y = tf_idf,
fill = articles.source_name)) +
geom_bar(stat = "identity", position = "dodge") +
coord_flip()+
labs(title = "TF-IDF: Top Words", x = "word") +
theme(legend.position = "bottom")
