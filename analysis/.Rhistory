summarise(mk_cls = mean(mathkind))
dim(mk_cls)
head(mk_class)
head(mk_cls)
dim(cl)
?join
cl %>% inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
# add columns to main data
cl_new <- cl %>% inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
dim(cl_new)
colnames(cl_new)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl_new)
str(cl_new)
# log likelihood
logLik(lme5)
unique(cl$classid)
cl %>% group_by(schoolid, classid) %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% arrange(schoolid, classid) %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% arrange(schoolid, classid) %>% n()
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% select(classid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% select(classid) %>% dim
312/107
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct()
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n_distinct(classid))
cl %>% group_by(schoolid, classid) %>% summarise(class_per_sch = n(), class_n = n_distinct(classid))
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n())
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n(schoolid))
cl %>% group_by(schoolid, classid) %>% summarise(class_n = count(schoolid))
cl %>% group_by(schoolid, classid)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(count(schoolid))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(n))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% arrange(cnt)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% arrange(desc(cnt))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% mean
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% mean
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% summarise(mean)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% summarise(mean(cnt))
312 / 107
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% select(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt)
hist(cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt))
# model fit
summary(lme5)
summary(lme5)
lme2$
lme2
attributes(lme2)
lme2$class
lme2
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
# convert IDs to factor
cols_factor <- c("classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
# unconditional means model
lme1 <- lmer(mathgain ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme1)
summary(lme1)
lme2 <- lmer(mathgain ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2)
summary(lme2)
lme3 <- lmer(mathgain ~ mathkind + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme3)
# model fit
summary(lme3)
lme4 <- lmer(mathgain ~ mathkind + ses + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme4)
# model fit
summary(lme4)
# add variables
ses_sch <- cl %>% group_by(schoolid) %>% summarise(ses_sch = mean(ses))
ses_cls <- cl %>% group_by(schoolid, classid) %>% summarise(ses_cls = mean(ses))
mk_sch <- cl %>% group_by(schoolid) %>% summarise(mk_sch = mean(mathkind))
mk_cls <- cl %>%
group_by(schoolid, classid) %>%
summarise(mk_cls = mean(mathkind))
# add columns to main data
cl_new <- cl %>%
inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl_new)
# log likelihood
logLik(lme5)
# log likelihood
logLik(lme5)
# model fit
summary(lme5)
ls()
rm(list = ls())
ls()
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
dim(cl)
str(cl)
# convert IDs to factor
cols_factor <- c("classid", "schoolid", "childid")
cols_factor
unique(cl$sex)
unique(cl$minority)
# convert IDs to factor
cols_factor <- c("sex", "minority", "classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
str(cl)
cl["sex"]
# unconditional means model
lme1 <- lmer(mathkind ~ (1 | schoolid), data = cl)
lme1
summary(lme1)
# log likelihood
logLik(lme1)
summary(lme1)
lme2 <- lmer(mathkind ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2)
summary(lme2)
lme1a <- lmer(mathkind ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme1a)
summary(lme1a)
anova(lme1, lme1a)
?anova
anova(lme1, lme1a)
anova(lme1, lme1a, refit = False)
anova(lme1, lme1a, refit = FALSE)
anova(lme1, lme1a, refit = TRUE)
anova(lme1, lme1a, refit = FALSE)
str(cl)
# generate 1st grade math scores
cl$math1st <- cl$mathkind = cl$mathgain
# generate 1st grade math scores
cl$math1st <- cl$mathkind + cl$mathgain
head(cl)
# model
# unconditional means model
lme2 <- lmer(math1st ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme2)
lme2a <- lmer(math1st ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2a)
summary(lme2a)
anova(lme2, lme2a, refit = FALSE)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid / classid), data = cl)
logLik(lme3)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid / classid), data = cl)
logLik(lme3)
lme3 <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3)
summary(lme3)
lme3a <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3a)
summary(lme3a)
lme3b <- lmer(math1st ~ ses + sex + minority + (1 | schoolid / classid),
data = cl)
logLik(lme3b)
summary(lme3b)
anova(lme3a, lme3b)
anova(lme3a, lme3b, refit = FALSE)
lmer::anova
colnames(cl)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl)
logLik(lme4a)
summary(lme4a)
cl$yt_sq <- cl$yearstea^2
cl$yt_cyb <- cl$yearstea^3
head(cl)
head(cl, 20)
12.54^2
12.54^3
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
logLik(lme4d)
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
cl$yt_sq <- cl$yearstea^2
cl$yt_cub <- cl$yearstea^3
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
logLik(lme4d)
summary(lme4d)
anova(lme4a, lme4d)
anova(lme4a, lme4d, refit = FALSE)
hea(cl, 20)
head(cl, 20)
unique(cl$ses)
len(unique(cl$ses))
length(unique(cl$ses))
length(unique(cl$schoolid))
length(unique(cl$classid))
unique(cl$childid)
cl$classid
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
# convert to factor
cols_factor <- c("sex", "minority", "classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
# unconditional means model
lme1 <- lmer(mathkind ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme1)
summary(lme1)
lme1a <- lmer(mathkind ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme1a)
summary(lme1a)
anova(lme1, lme1a, refit = FALSE)
# generate 1st grade math scores
cl$math1st <- cl$mathkind + cl$mathgain
# model
# unconditional means model
lme2 <- lmer(math1st ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme2)
lme2a <- lmer(math1st ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2a)
summary(lme2a)
anova(lme2, lme2a, refit = FALSE)
lme3a <- lmer(math1st ~ ses + sex + minority + (1 | schoolid), data = cl)
logLik(lme3a)
summary(lme3a)
lme3b <- lmer(math1st ~ ses + sex + minority + (1 | schoolid / classid),
data = cl)
logLik(lme3b)
summary(lme3b)
anova(lme3a, lme3b, refit = FALSE)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl)
logLik(lme4a)
summary(lme4a)
cl$yt_sq <- cl$yearstea^2
cl$yt_cub <- cl$yearstea^3
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
logLik(lme4d)
summary(lme4d)
anova(lme4a, lme4d, refit = FALSE)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl, REML = FALSE)
logLik(lme4a)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl)
logLik(lme4a)
lme4a <- lmer(math1st ~ ses + sex + minority + yearstea + (1 | schoolid / classid),
data = cl, REML = FALSE)
logLik(lme4a)
```{r}
summary(lme4a)
cl$yt_sq <- cl$yearstea^2
cl$yt_cub <- cl$yearstea^3
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl,
REML = FALSE)
logLik(lme4d)
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl)
logLik(lme4d)
lme4d <- lmer(math1st ~ ses + sex + minority + yearstea + yt_sq + yt_cub +
(1 | schoolid / classid),
data = cl,
REML = FALSE)
logLik(lme4d)
summary(lme4d)
anova(lme4a, lme4d, refit = FALSE)
anova(lme4a, lme4d)
anova(lme4a, lme4d, refit = FALSE)
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
anova(lme1, lme1a, refit = TRUE)
anova(lme1, lme1a, refit = FALSE)
anova(lme2, lme2a, refit = TRUE)
anova(lme2, lme2a, refit = FALSE)
anova(lme3a, lme3b, refit = TRUE)
anova(lme3a, lme3b, refit = FALSE)
rm(list = ls())
ls()
rm(list = ls())
# not run
setwd("C:/Users/apagta950/Documents/NYU/Courses/Spring 2021/MDML/Final Project/US-News-NLP/analysis")
library(dplyr)
library(stringr)
library(readr)
# Combine news sources
#######
# CNN #
#######
articles_cnn <- read_csv("../data/news_data_cnn.csv") %>%
filter(text != "N/A") %>%
mutate(text = str_remove_all(text, "CNN")) %>%
mutate(text = str_replace(text, fixed("()"), "")) %>%
mutate(text = str_replace(text, fixed("( Business)"), "")) %>%
mutate(text = str_replace_all(text, "[\n]", "")) %>%
mutate(text = gsub("\\\"", "", text, fixed = TRUE)) %>%
mutate(text = gsub("\"", "", text, fixed = TRUE))
###############
# Add Reuters #
###############
articles_cnn_reuters <- bind_rows(articles_cnn,
read_csv("../data/news_data_reuters.csv"))
# read wsj
articles_wsj <- read_csv("../data/news_wsj_new.csv")
# read bbc
articles_bbc <- read_csv("../data/news_bbc_new.csv")
# read wsj
articles_wsj <- read_csv("../data/news_wsj_new.csv")
# read bbc
articles_bbc <- read_csv("../data/news_bbc_new.csv") %>% select(-text)
colnames(articles_bbc)
# read wsj and bbc
articles_bbc_wsj <- bind_rows(articles_wsj, articles_bbc)
dim(articles_bbc_wsj)
colnames(articles_bbc_wsj)
# read wsj
articles_wsj <- read_csv("../data/news_wsj_new.csv")
# read bbc
articles_bbc <- read_csv("../data/news_bbc_new.csv") %>%
select(-text) %>%
mutate(text = text_new)
# read wsj and bbc
articles_bbc_wsj <- bind_rows(articles_wsj, articles_bbc)
colnames(articles_bbc_wsj)
# read bbc
articles_bbc <- read_csv("../data/news_bbc_new.csv") %>%
mutate(text = text_new) %>%
select(-text_new) %>%
# read wsj and bbc
articles_bbc_wsj <- bind_rows(articles_wsj, articles_bbc)
# read bbc
articles_bbc <- read_csv("../data/news_bbc_new.csv") %>%
mutate(text = text_new) %>%
select(-text_new)
colnames(articles_bbc)
# read wsj and bbc
articles_bbc_wsj <- bind_rows(articles_wsj, articles_bbc)
dim(articles_bbc_wsj)
colnames(articles_bbc_wsj)
colnames(articles_wsj)
# read wsj
articles_wsj <- read_csv("../data/news_wsj_new.csv") %>%
mutate(text = text_new) %>%
select(-text_new)
# read bbc
articles_bbc <- read_csv("../data/news_bbc_new.csv") %>%
mutate(text = text_new) %>%
select(-text_new)
# read wsj and bbc
articles_bbc_wsj <- bind_rows(articles_wsj, articles_bbc)
dim(articles_bbc_wsj)
colnames(articles_bbc_wsj)
# not run
setwd("C:/Users/apagta950/Documents/NYU/Courses/Spring 2021/MDML/Final Project/US-News-NLP/analysis")
library(dplyr)
library(stringr)
library(readr)
# Combine news sources
#######
# CNN #
#######
articles_cnn <- read_csv("../data/news_data_cnn.csv") %>%
filter(text != "N/A") %>%
mutate(text = str_remove_all(text, "CNN")) %>%
mutate(text = str_replace(text, fixed("()"), "")) %>%
mutate(text = str_replace(text, fixed("( Business)"), "")) %>%
mutate(text = str_replace_all(text, "[\n]", "")) %>%
mutate(text = gsub("\\\"", "", text, fixed = TRUE)) %>%
mutate(text = gsub("\"", "", text, fixed = TRUE))
###############
# Add Reuters #
###############
articles_cnn_reuters <- bind_rows(articles_cnn,
read_csv("../data/news_data_reuters.csv"))
###############
# WSJ and BBC #
###############
# read wsj
articles_wsj <- read_csv("../data/news_wsj_new.csv") %>%
mutate(text = text_new) %>%
select(-text_new)
# read bbc
articles_bbc <- read_csv("../data/news_bbc_new.csv") %>%
mutate(text = text_new) %>%
select(-text_new)
# read wsj and bbc
articles_bbc_wsj <- bind_rows(articles_wsj, articles_bbc)
# remove first three columns and consolidate source names
articles_bbc_wsj <- articles_bbc_wsj %>%
select(-c(X1, X.1, X)) %>%
mutate(articles.source_name =
if_else(articles.source_name == "Wall Street Journal",
"The Wall Street Journal",
articles.source_name))
########################
# Combine news sources #
########################
# combine articles
articles <- bind_rows(articles_cnn_reuters, articles_bbc_wsj)
articles %>% group_by(articles.source_name) %>% summarise(n())
# write file
write_csv(articles, file = "../data/news_all.csv")
dim(articles_cnn_reuters)
dim(articles_bbc_wsj)
colnames(articles_bbc_wsj)
# not run
setwd("C:/Users/apagta950/Documents/NYU/Courses/Spring 2021/MDML/Final Project/US-News-NLP/analysis")
library(dplyr)
library(stringr)
library(readr)
# Combine news sources
#######
# CNN #
#######
articles_cnn <- read_csv("../data/news_data_cnn.csv") %>%
filter(text != "N/A") %>%
mutate(text = str_remove_all(text, "CNN")) %>%
mutate(text = str_replace(text, fixed("()"), "")) %>%
mutate(text = str_replace(text, fixed("( Business)"), "")) %>%
mutate(text = str_replace_all(text, "[\n]", "")) %>%
mutate(text = gsub("\\\"", "", text, fixed = TRUE)) %>%
mutate(text = gsub("\"", "", text, fixed = TRUE))
###############
# Add Reuters #
###############
articles_cnn_reuters <- bind_rows(articles_cnn,
read_csv("../data/news_data_reuters.csv"))
###############
# WSJ and BBC #
###############
# read wsj
articles_wsj <- read_csv("../data/news_wsj_new.csv") %>%
mutate(text = text_new) %>%
select(-text_new)
# read bbc
articles_bbc <- read_csv("../data/news_bbc_new.csv") %>%
mutate(text = text_new) %>%
select(-text_new)
# read wsj and bbc
articles_bbc_wsj <- bind_rows(articles_wsj, articles_bbc)
# remove first three columns and consolidate source names
articles_bbc_wsj <- articles_bbc_wsj %>%
select(-c(X1, X.1, X, X.2)) %>%
mutate(articles.source_name =
if_else(articles.source_name == "Wall Street Journal",
"The Wall Street Journal",
articles.source_name))
########################
# Combine news sources #
########################
# combine articles
articles <- bind_rows(articles_cnn_reuters, articles_bbc_wsj)
articles %>% group_by(articles.source_name) %>% summarise(n())
# write file
write_csv(articles, file = "../data/news_all.csv")
