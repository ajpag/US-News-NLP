# Validation Metrics #
######################
gbm_accuracy <- mean(gbm_preds == articles_test$articles.source_name)
gbm_accuracy2 <- mean(gbm_preds2 == articles_test$articles.source_name)
gbm_accuracy3 <- mean(gbm_preds3 == articles_test$articles.source_name)
gbm_accuracy4 <- mean(gbm_preds4 == articles_test$articles.source_name)
paste("GBM Model 1 Accuracy (Topics):", round(gbm_accuracy, 3))
paste("GBM Model 2 Accuracy (Keywords):", round(gbm_accuracy2, 3))
paste("GBM Model 3 Accuracy (Topic Keywords):", round(gbm_accuracy3, 3))
paste("GBM Model 4 Accuracy (All Features):", round(gbm_accuracy4, 3))
#######
# AUC #
#######
# auc
auc_ <- multiclass.roc(articles_test$articles.source_name, gbm_prob)
auc2 <- multiclass.roc(articles_test$articles.source_name, gbm_prob2)
auc3 <- multiclass.roc(articles_test$articles.source_name, gbm_prob3)
auc4 <- multiclass.roc(articles_test$articles.source_name, gbm_prob4)
paste("GBM Model 1 AUC (Topics):", round(auc_$auc, 3))
paste("GBM Model 2 AUC (Keywords):", round(auc2$auc, 3))
paste("GBM Model 3 AUC (Topic Keywords):", round(auc3$auc, 3))
paste("GBM Model 4 AUC (Topic Keywords):", round(auc4$auc, 3))
auc2 <- multiclass.roc(articles_test$articles.source_name, gbm_prob2)
# probabilities on test set
gbm_prob2 <- predict(gbm_fit2, articles_test, type = "prob")
# fit model
gbm_fit2 <- train(articles.source_name ~ . - avg_sentiment_afinn_sent,
data = gbm_train2,
method = "gbm")
setwd()
getwd()
# not run
# setwd("C:/Users/apagta950/Documents/NYU/Courses/Spring 2021/MDML/Final Project/US-News-NLP/analysis")
library(dplyr)
library(caret) # Gradient Boosting Machine
library(gbm) # need for feature importance
library(readr)
library(pROC) # multi-class ROC and AUC
seed <- 14
set.seed(seed)
# Purpose: Predict the news source
data_dir <- "../data/"
figures_dir <- "../figures/"
articles <- read_csv(paste0(data_dir, "news_model_input.csv"))
# filter to columns for modeling
articles_input <- articles %>%
select(-c(datetime, timestamp, countArticles, articles.article_url,
articles.title, articles.description,
articles.description_with_tag, articles.published_datetime,
articles.published_timestamp, articles.image_url,
articles.source_url, articles.source_domain, text,
word_count,
word_count_sentiment, published_hour_et)) %>%
drop_na()
# Assess bias in topic probabibilities
# rescale to integers for Chi-Square test
articles_topic_prob_sc <- articles %>%
select(articles.source_name | contains("topic")) %>%
group_by(articles.source_name) %>%
drop_na() %>%
summarise(round((across(contains("prob"), mean))*100, 0))
# convert to matrix
articles_sc_mat <- articles_topic_prob_sc %>%
select(-articles.source_name) %>%
as.matrix
# provide row names
rownames(articles_sc_mat) <- articles_topic_prob_sc$articles.source_name
# convert to table
articles_sc_mat <- as.table(articles_sc_mat)
# See "topic_probabilities_news_source.png" in /figures to visualize avg probabilities
# conduct chi-square test
print(chisq.test(articles_sc_mat))
# Assess bias in average sentiment
# rescale to non-negative integers for Chi-Square test
articles_sentiment_sc <- articles %>%
select(articles.source_name, avg_sentiment_afinn_sent) %>%
group_by(articles.source_name) %>%
drop_na() %>%
summarise(avg_sentiment = mean(avg_sentiment_afinn_sent)) %>%
mutate(avg_sentiment_sc = -round(avg_sentiment * 100, 0))
# See "sentence_afinn_sentiment.png" in /figures to visualize avg sentiment
# convert to matrix
articles_sentiment_sc_mat <- articles_sentiment_sc %>%
select(avg_sentiment_sc) %>%
as.matrix
# provide row names
rownames(articles_sentiment_sc_mat) <- articles_sentiment_sc$articles.source_name
# convert to table
articles_sentiment_sc_mat <- as.table(articles_sentiment_sc_mat)
# conduct chi-square test
print(chisq.test(articles_sentiment_sc_mat))
articles_word_count <- articles %>%
select(articles.source_name, word_count) %>%
group_by(articles.source_name) %>%
summarise(avg_word_count = mean(word_count)) %>%
mutate(avg_word_count_chi = round(avg_word_count, 0))
# plot average word count
p1 <- articles_word_count %>%
ggplot(aes(x = articles.source_name, y = avg_word_count)) +
geom_bar(stat = "identity") +
labs(title = "Average Word Count per Article")
# convert to matrix
articles_word_count_mat <- as.matrix(articles_word_count$avg_word_count_chi)
rownames(articles_word_count_mat) <- articles_word_count$articles.source_name
# chi-square test
chisq.test(articles_word_count_mat)
articles_train
# train / test split
test_rate <- .2
articles_train <- articles_input %>% sample_frac(size = 1 - test_rate)
articles_test <- articles_input[-c(pull(articles_train %>% select(document))), ]
bind_rows(articles_train %>% mutate(set = "train"),
articles_test %>% mutate(set = "test")) %>%
group_by(articles.source_name, set) %>%
summarise(article_count = n()) %>%
ggplot(aes(x = articles.source_name, y = article_count)) +
geom_bar(stat = "identity", position = "dodge") +
facet_wrap(~set)
gbm_fit
gbm_accuracy <- mean(gbm_preds == articles_test$articles.source_name)
paste("GBM Model 1 Accuracy (Topics):", round(gbm_accuracy, 3))
paste("GBM Model 2 Accuracy (Keywords):", round(gbm_accuracy2, 3))
paste("GBM Model 3 Accuracy (Topic Keywords):", round(gbm_accuracy3, 3))
paste("GBM Model 4 Accuracy (All Features):", round(gbm_accuracy4, 3))
gbm_train2 <- articles_train %>%
select(contains("_sentiment") |
c(published_dow, articles.source_name))
# fit model
gbm_fit2 <- train(articles.source_name ~ . - avg_sentiment_afinn_sent,
data = gbm_train2,
method = "gbm")
# predictions on test set
gbm_preds2 <- predict(gbm_fit2, articles_test)
# probabilities on test set
gbm_prob2 <- predict(gbm_fit2, articles_test, type = "prob")
paste("GBM Model 1 Accuracy (Topics):", round(gbm_accuracy, 3))
paste("GBM Model 2 Accuracy (Keywords):", round(gbm_accuracy2, 3))
paste("GBM Model 3 Accuracy (Topic Keywords):", round(gbm_accuracy3, 3))
paste("GBM Model 4 Accuracy (All Features):", round(gbm_accuracy4, 3))
# results dataframe
gbm_results <- data.frame(model = c("gbm_topic_lda", "gbm_keywords",
"gbm_topic_keywods", "gbm_all_features"),
accuracy = round(c(gbm_accuracy, gbm_accuracy2,
gbm_accuracy3, gbm_accuracy4), 2),
auc = round(c(auc_, auc2, auc3, auc4), 2))
gbm_accuracy2 <- mean(gbm_preds2 == articles_test$articles.source_name)
auc2 <- multiclass.roc(articles_test$articles.source_name, gbm_prob2)
# results dataframe
gbm_results <- data.frame(model = c("gbm_topic_lda", "gbm_keywords",
"gbm_topic_keywods", "gbm_all_features"),
accuracy = round(c(gbm_accuracy, gbm_accuracy2,
gbm_accuracy3, gbm_accuracy4), 2),
auc = round(c(auc_, auc2, auc3, auc4), 2))
auc_
auc_$auc
# results dataframe
gbm_results <- data.frame(model = c("gbm_topic_lda", "gbm_keywords",
"gbm_topic_keywods", "gbm_all_features"),
accuracy = round(c(gbm_accuracy, gbm_accuracy2,
gbm_accuracy3, gbm_accuracy4), 2),
auc = round(c(auc_$auc, auc2$auc, auc3$auc auc4$auc), 2))
# results dataframe
gbm_results <- data.frame(model = c("gbm_topic_lda", "gbm_keywords",
"gbm_topic_keywods", "gbm_all_features"),
accuracy = round(c(gbm_accuracy, gbm_accuracy2,
gbm_accuracy3, gbm_accuracy4), 2),
auc = round(c(auc_$auc, auc2$auc, auc3$auc, auc4$auc), 2))
gbm_results
ggsave(gbm_results, file = paste0(figures_dir, "gbm_results.png"))
# save results
write_csv(paste0(figures_dir, "gbm_results.png")
# save results
write_csv(paste0(figures_dir, "gbm_results.png"))
# save results
write_csv(gbm_results, paste0(figures_dir, "gbm_results.png"))
# save results
write_csv(gbm_results, paste0(figures_dir, "gbm_results.csv"))
confusionMatrix(gbm_fit)
confusionMatrix(gbm_fit2)
confusionMatrix(gbm_fit3)
confusionMatrix(gbm_fit4)
t <- confusionMatrix(gbm_fit)
t$table
t$norm
t$B
t$text
summary*t
summar(t)
summary(t)
confusionMatrix(gbm_fit)
?confusionMatrix
?confusionMatrix
library(ModelMetrics)
confusionMatrix(gbm_fit)
confusionMatrix(articles_train, gbm_fit$pred)
confusionMatrix(articles_train, gbm_fit$pred)
gbm_fit$pred
confusionMatrix(gbm_fit)
caret::confusionMatrix(gbm_fit)
?caret::confusionMatrix
t <- confusionMatrix.train(gbm_fit)
t
t <- confusionMatrix(gbm_fit)
t <- caret::confusionMatrix(gbm_fit)
t
clas(gbm_fit)
class(gbm_fit)
?confusionMatrix.train
class(confusionMatrix.train(gbm_fit))
attributes(confusionMatrix.train(gbm_fit))
t <- confusionMatrix.train(gbm_fit)
t$table
class(t$table)
t$table
Diagonal(t$table)
as.matrix(t$table)
diag(as.matrix(t$table))
sum(diag(as.matrix(t$table))) / sum(as.matrix(t$table))
cm1 <- as.matrix(confusionMatrix(gbm_fit))
cm2 <- as.matrix(confusionMatrix(gbm_fit2))
cm3 <- as.matrix(confusionMatrix(gbm_fit3))
cm4 <- as.matrix(confusionMatrix(gbm_fit4))
library(caret)
cm1 <- as.matrix(confusionMatrix(gbm_fit))
cm2 <- as.matrix(confusionMatrix(gbm_fit2))
cm3 <- as.matrix(confusionMatrix(gbm_fit3))
cm4 <- as.matrix(confusionMatrix(gbm_fit4))
cm1 <- as.matrix(caret::confusionMatrix(gbm_fit))
cm2 <- as.matrix(caret::confusionMatrix(gbm_fit2))
cm3 <- as.matrix(caret::confusionMatrix(gbm_fit3))
cm4 <- as.matrix(caret::confusionMatrix(gbm_fit4))
# confusion matrix for training data
cm1 <- as.matrix(caret::confusionMatrix.train(gbm_fit))
cm2 <- as.matrix(caret::confusionMatrix.train(gbm_fit2))
cm3 <- as.matrix(caret::confusionMatrix.train(gbm_fit3))
cm4 <- as.matrix(caret::confusionMatrix.train(gbm_fit4))
sum(diag(cm1)) / sum(cm1)
cm1
cm1
# confusion matrix for training data
cm1 <- as.matrix(caret::confusionMatrix.train(gbm_fit))
cm1
as.matrix(caret::confusionMatrix.train(gbm_fit))
as.matrix(caret::confusionMatrix(gbm_fit))
confusionMatrix(gbm_fit)
caret::confusionMatrix(gbm_fit)
t <- caret::confusionMatrix(gbm_fit)
# confusion matrix for training data
cm1 <- as.matrix(caret::confusionMatrix(gbm_fit)$table)
cm2 <- as.matrix(caret::confusionMatrix.train(gbm_fit2)$table)
cm3 <- as.matrix(caret::confusionMatrix.train(gbm_fit3)$table)
cm4 <- as.matrix(caret::confusionMatrix.train(gbm_fit4)$table)
cm1
cm2
cm3
cm4
gbm1_train_acc <- sum(diag(cm1)) / sum(cm1)
gbm1_train_acc
# training accuracy
gbm1_train_acc <- sum(diag(cm1)) / sum(cm1)
gbm2_train_acc <- sum(diag(cm2)) / sum(cm2)
gbm3_train_acc <- sum(diag(cm3)) / sum(cm3)
gbm4_train_acc <- sum(diag(cm4)) / sum(cm4)
gbm1_train_acc
gbm2_train_acc
gbm3_train_acc
gbm4_train_acc
caret::confusionMatrix(gbm_fit)
caret::confusionMatrix.train(gbm_fit3)
caret::confusionMatrix.train(gbm_fit4)
# results dataframe
gbm_results <- data.frame(model = c("gbm_topic_lda", "gbm_keywords",
"gbm_topic_keywods", "gbm_all_features"),
train_accuracy = c(gbm1_train_acc, gbm2_train_acc,
gbm3_train_acc, gbm4_train_acc),
test_accuracy = round(c(gbm_accuracy, gbm_accuracy2,
gbm_accuracy3, gbm_accuracy4), 2),
auc = round(c(auc_$auc, auc2$auc, auc3$auc, auc4$auc), 2))
# save results
write_csv(gbm_results, paste0(figures_dir, "gbm_results.csv"))
# results dataframe
gbm_results <- data.frame(model = c("gbm_topic_lda", "gbm_keywords",
"gbm_topic_keywods", "gbm_all_features"),
train_accuracy = round(c(gbm1_train_acc, gbm2_train_acc,
gbm3_train_acc, gbm4_train_acc), 2),
test_accuracy = round(c(gbm_accuracy, gbm_accuracy2,
gbm_accuracy3, gbm_accuracy4), 2),
auc = round(c(auc_$auc, auc2$auc, auc3$auc, auc4$auc), 2))
gbm_results
# save results
write_csv(gbm_results, paste0(figures_dir, "gbm_results.csv"))
# save results
write_csv(gbm_results, paste0(figures_dir, "gbm_results.csv"))
library(dplyr)
library(ggplot2)
library(lme4)
library(tidyr)
set.seed(2042001)
######################## 1. Generate Simulated Data ############################
classrooms <- 100
# students per classroom
students <- 200
# generate simulated data
cl <- data.frame(
# predictor
x = runif(students * classrooms),
# classroom random effects
eta = rep(rnorm(classrooms, 0, sqrt(2)), each = students),
classid = as.factor(rep(c(1:classrooms), each = students)),
# student error
epsilon = rnorm(students * classrooms, 0, sqrt(2))
) %>% mutate(y = x + eta + epsilon)
# visualize generated data
print(p1 <- cl %>%
pivot_longer(cols = -classid) %>%
ggplot(aes(x = value)) +
geom_histogram() +
facet_wrap(~name, scales = "free") +
labs(title = "Generated Data"))
# check class id distribution
print(p2 <- cl %>%
group_by(classid) %>%
summarise(n = n()) %>%
ggplot(aes(x = classid, y = n)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust = 1)) +
labs(title = "Class ID Distribution"))
# descriptive stats
summary(cl)
########################## 2. Fit Model ########################################
lme1 <- lmer(y ~ x + (1 | classid), data = cl)
summary(lme1)
summary(lme2)
summary(lme2)
library(dplyr)
library(ggplot2)
library(lme4)
library(tidyr)
set.seed(2042001)
######################## 1. Generate Simulated Data ############################
classrooms <- 100
# students per classroom
students <- 200
# generate simulated data
cl <- data.frame(
# predictor
x = runif(students * classrooms),
# classroom random effects
eta = rep(rnorm(classrooms, 0, sqrt(2)), each = students),
classid = as.factor(rep(c(1:classrooms), each = students)),
# student error
epsilon = rnorm(students * classrooms, 0, sqrt(2))
) %>% mutate(y = x + eta + epsilon)
# visualize generated data
print(p1 <- cl %>%
pivot_longer(cols = -classid) %>%
ggplot(aes(x = value)) +
geom_histogram() +
facet_wrap(~name, scales = "free") +
labs(title = "Generated Data"))
# check class id distribution
print(p2 <- cl %>%
group_by(classid) %>%
summarise(n = n()) %>%
ggplot(aes(x = classid, y = n)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust = 1)) +
labs(title = "Class ID Distribution"))
# descriptive stats
summary(cl)
########################## 2. Fit Model ########################################
lme1 <- lmer(y ~ x + (1 | classid), data = cl)
summary(lme1)
# coefficient on x
x_coef <- summary(lme1)$coef["x", "Estimate"]
paste("Coefficient:", x_coef)
# check 95% confidence band
confint_ <- confint.merMod(lme1)
paste("95% confidence interval:", confint_["x", ])
confint_check <- function(confint_, coef_truth = 1) {
# checks if confidence interval covers the actual coefficient
# confint_: matrix object with confidence intervals
# coef_truth: actual coefficient used to generate the data
lower_bound <- confint_["x", 1]
upper_bound <- confint_["x", 2]
return(coef_truth >= lower_bound & coef_truth <= upper_bound)
}
# The 95% confidence band covers the actual coefficient used to generate the data
paste("Does the CI cover the actual coefficient (Model 1)?",
confint_check(confint_))
########################## 3. Simulate II ######################################
# make copy
# INCLUDE OR EXCLUDE Z IN MODEL FIT?
cl2 <- cl %>%
mutate(z = rbinom(nrow(cl), 1, prob = .5),
y = ifelse(z == 1, NA, y))
lme2 <- lmer(y ~ x + (1 | classid), data = cl2 %>% select(-z))
summary(lme2)
# There is a slighy increase in the X coefficient
# The 95% confidence band covers the truth used to generate the data.
confint2 <- confint.merMod(lme2)
paste("Does the CI cover the actual coefficient (Model 2)?",
confint_check(confint2))
# DISCUSS
# WHY DOES CI INCREASE AFTER APPLYING MCAR
# ISN'T PROCESS FOR Z MAR?
# sample size for model 2
paste("Sample size for model 2:", nrow(cl2 %>% drop_na()))
########################## 4. Simulate III #####################################
# MAR VS. MCAR - IMPLICATIONS FOR MODEL
# IS PROCESS FOR Z MCAR INSTEAF OF MAR, SINCE IT IS CONDITIONAL ON X?
cl3 <- cl %>%
mutate(z = rbinom(nrow(cl), 1, x),
y = ifelse(z == 1, NA, y))
lme3 <- lmer(y ~ x + (1 | classid), data = cl3 %>% select(-z))
summary(lme3)
# There is a slight increase to the X coefficient
# check 95% confidence band
confint3 <- confint.merMod(lme3)
# The 95% confidence band covers the truth used to generate the data.
paste("Does the CI cover the actual coefficient (Model 3)?",
confint_check(confint3))
# DISCUSS: WHY DOES CI INCREASE
# sample size for model 3
paste("Sample size for model 3:", nrow(cl3 %>% drop_na()))
########################## 5. Simulate IV ######################################
expit <- function(x) {exp(x) / (1 + exp(x))}
cl4 <- cl %>%
mutate(z = rbinom(nrow(cl), 1, expit(y)),
y = ifelse(z == 1, NA, y))
lme4 <- lmer(y ~ x + (1 | classid), data = cl4 %>% select(-z))
summary(lme4)
# There is a decrease to the X coefficient
# check 95% confidence band
confint4 <- confint.merMod(lme4)
# The 95% confidence band does not cover the truth used to generate the data.
paste("Does the CI cover the actual coefficient (Model 4)?",
confint_check(confint4))
# WHY DOES CI INCREASE AFTER APPLYING MAR
summary(cl4$x)
# sample size for model 4
paste("Sample size for model 4:", nrow(cl4 %>% drop_na()))
# CIs
confints <- rbind(confint_["x", ], confint2["x", ],
confint3["x", ], confint4["x", ])
rownames(confints) <- c("Model 1 (full data)",
"Model 2 (Z ~ Bern(.5))",
"Model 3 (Z ~ Bern(X))",
"Model 4 (Z ~ Bern(expit(y)))")
print(confints)
############### Post Analysis ##################################################
# combine all data frames
cl_all <- rbind(cl %>% mutate(z = NA, model = 1),
cl2 %>% mutate(model = 2),
cl3 %>% mutate(model = 3),
cl4 %>% mutate(model = 4))
# model sample size
print(p3 <- cl_all %>%
filter(z == 0 | is.na(z)) %>%
group_by(model, z) %>%
summarise(sample_size = n()) %>%
ggplot(aes(x = model, y = sample_size)) +
geom_bar(stat = "identity") +
labs(title = "Model sample sizes"))
# distribution of (expit(y))
print(p4 <- hist(expit(cl$y)))
# distribution of Z values
print(p5 <- cl_all %>%
group_by(model, z) %>%
summarise(n = n()) %>%
ggplot(aes(x = model, y = n, fill = as.factor(z))) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Distribution of Z") +
theme(legend.position = "bottom"))
# distribution of X given Z cross different models
print(p6 <- cl_all %>%
ggplot(aes(x = x)) +
geom_histogram(alpha = 0.5) +
facet_grid(z~model) +
labs(title = "Distribution of X Given Z", y = "z"))
# distribution of y given Z cross different models
print(p7 <- cl_all %>%
ggplot(aes(x = y, fill = as.factor(model))) +
geom_histogram(alpha = 0.5) +
labs(title = "Distribution of Y Given Z", y = "z") +
theme(legend.position = "bottom"))
p3
p2
p1
cl
summary(lme1)
summary(lme2)
summary(lme1)$coef
summary(lme2)$coef
summary(lme3)$coef
summary(lme4)$coef
varImp(gbm_fit)
varImp(gbm_fit2)
varImp(gbm_fit3)
varImp(gbm_fit4)
class(varImp(gbm_fit4))
as.data.frame(varImp(gbm_fit4))
# plot variable importance
varImp(gbm_fit)
varImp(gbm_fit2)
varImp(gbm_fit3)
varImp(gbm_fit4)
# plot variable importance
varImp(gbm_fit)
varImp(gbm_fit2)
varImp(gbm_fit3)
varImp(gbm_fit4)
