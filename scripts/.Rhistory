colnames(cl)
# add SES
summary(lme2 <- lmer(mathkind ~ ses + sex + minority + (1 | schoolid), data = cl))
# add house POV
summary(lme2 <- lmer(mathkind ~ ses + sex + minority + housepov + (1 | schoolid),
data = cl))
# add house POV
summary(lme2 <- lmer(mathkind ~ ses + sex + minority + mathgain + housepov + (1 | schoolid),
data = cl))
sort(tapply(cl$mathgain, cl$schoolid, mean))
plot(sort(tapply(cl$mathgain, cl$schoolid, mean)))
logLik(lme1)
# log likelihood
logLik(lme1)
summary(lme2 <- lmer(mathkind ~ ses + sex + (1 | schoolid), data = cl))
summary(lme1)
knitr::opts_chunk$set(echo=TRUE,tidy=TRUE)
# make sure dir struct is like: "~/Dropbox/Teaching/MLM Nested_Sp21/Handouts"
library(lattice)
library(ggplot2)
#set "vanillaR" flag for use of ggplot or not (when implemented)
vanillaR <- F
showR <- T
require(lme4)
require(lmerTest)
dat <- read.csv("../Datasets/classroom.csv")
require(lme4)
require(lmerTest)
dat <- read.csv("classroom.csv")
#simple regression
fit1 <- lm(mathkind~ses,data=dat)
print(summary(fit1))
dat$pred1 <- predict(fit1)
if (vanillaR) {
xyplot(mathkind+pred1~ses|schoolid,data=dat[dat$schoolid<25,],type=list('p','r'),distribute.type=T)
} else {
ggplot(data=subset(dat,schoolid<25),aes(y=mathkind,x=ses))+geom_point()+facet_wrap(~schoolid,ncol = 6)+geom_line(aes(y=pred1,x=ses),col=2)
}
dat$res1 <- residuals(fit1)
ord <- order(unlist(tapply(dat$res1,dat$schoolid,median)))
if (vanillaR) {
boxplot(split(dat$res1,dat$schoolid)[ord])
} else {
ggplot(dat, aes(x = reorder(schoolid, res1, FUN=median), y = res1)) + geom_boxplot()
}
dim(dat)
unique(dat$schoolid)
length(dat$schoolid)
length(unique(dat$schoolid))
dat$res1
dim(res1)
dim(dat$res1)
length(dat$res1)
res1mean <- tapply(dat$res1,dat$schoolid,mean,na.rm=T)
plot(res1mean)
plot(res1mean)
length(res1mean)
plot(dat$pred1, dat$res1)
plot(res1mean)
plot(dat$ses, dat$mathkind)
plot(dat$ses, dat$pred1)
plot(dat$ses, dat$mathkind)
plot(dat$ses, dat$pred1)
plot(dat$ses, dat$mathkind)
plot(dat$ses, dat$pred1)
dat %>% ggplot(aes(x = ses, y = mathkind)) + geom_smooth(method = "lm")
library(tidyverse)
dat %>% ggplot(aes(x = ses, y = mathkind)) + geom_smooth(method = "lm")
dat %>% ggplot(aes(x = ses, y = mathkind)) + geom_point()
dat %>% ggplot(aes(x = ses, y = mathkind)) + geom_point() + geom_smooth()
dat %>% ggplot(aes(x = ses, y = mathkind)) + geom_point() + geom_smooth(method = "lm")
plot(fit1)
plot(fit1)
hist(res1mean)
mean(res1mean)
res1mean
dat %>% filter(schoolid == 107)
dat %>% filter(schoolid == 107) %>% select(res1) %>% summarise(mean)
dat %>% filter(schoolid == 107) %>% select(res1) %>% summarise(mean(res1))
dat %>% filter(schoolid == 1) %>% select(res1) %>% summarise(mean(res1))
dta
library(foreign)
library(lme4)
library(lmerTest)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
# convert IDs to factor
cols_factor <- c("classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
length(unique(cl$ses))
hist(cl$ses)
cor(cl$ses, cl$mathkind)
cor(cl)
# unconditional means model
lme1 <- lmer(mathgain ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme1)
str(cl)
summary(lme1)
str(cl)
# unconditional means model
lme2 <- lmer(mathgain ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2)
summary(lme2)
?ranova
ranova(lme2)
lme3 <- lmer(mathgain ~  mathkind + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme3)
# model fit
summary(lme3)
length(unique(cl$mathkind))
length(unique(cl$classid))
length(unique(cl$schoolid))
hist(cl$schoolid)
hist(cl$mathkind)
cor(cl$mathkind, cl$mathgain)
plot(cl$mathkind, cl$mathgain)
lme4 <- lmer(mathgain ~ mathkind + ses + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme4)
summary(lme4)
?summary
tapply(cl$mathkind, index = 1, fun = mean)
tapply(cl$schoolid, $mathkind, cl$mathkind, fun = mean)
tapply(cl$schoolid, cl$mathkind, cl$mathkind, fun = mean)
tapply(cl$schoolid, cl$mathkind, mean)
tapply(cl$mathkind, cl$schoolid, mean)
boxplot(cl$mathkind)
boxplot(cl$mathkind, cl$schoolid)
boxplot(cl[ , c("mathkind", "schoolid")])
boxplot(cl[ , "schoolid"])
tapply(cl$schoolid, cl$mathkind, mean)
tapply(cl$mathkind, cl$schoolid, mean)
plot(tapply(cl$mathkind, cl$schoolid, mean))
plot(sort(tapply(cl$mathkind, cl$schoolid, mean)))
plot(sort(cl$mathkind))
plot(sort(tapply(cl$mathkind, cl$schoolid, mean)))
plot(sort(cl$mathkind))
library(dplyr)
# add variables
cl %>% group_by(schoolid) %>% summarise(ses_sch = mean(ses))
unique(cl$classid)
dim(cl)
ses_cls <- cl %>% group_by(schoolid, classid) %>% summarise(ses_cls = mean(ses))
dim(ses_cls)
head(ses_cls)
# add variables
ses_sch <- cl %>% group_by(schoolid) %>% summarise(ses_sch = mean(ses))
ses_cls <- cl %>% group_by(schoolid, classid) %>% summarise(ses_cls = mean(ses))
mk_sch <- cl %>% group_by(schoolid) %>% summarise(mk_sch = mean(mathkind))
mk_cls <- cl %>%
group_by(schoolid, classid) %>%
summarise(mk_cls = mean(mathkind))
dim(mk_cls)
head(mk_class)
head(mk_cls)
dim(cl)
?join
cl %>% inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
# add columns to main data
cl_new <- cl %>% inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
dim(cl_new)
colnames(cl_new)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl_new)
str(cl_new)
# log likelihood
logLik(lme5)
unique(cl$classid)
cl %>% group_by(schoolid, classid) %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% arrange(schoolid, classid) %>% print(n = 40)
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% arrange(schoolid, classid) %>% n()
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% select(classid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct() %>% select(classid) %>% dim
312/107
cl %>% group_by(schoolid, classid) %>% select(schoolid, classid) %>% distinct()
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n_distinct(classid))
cl %>% group_by(schoolid, classid) %>% summarise(class_per_sch = n(), class_n = n_distinct(classid))
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n())
cl %>% group_by(schoolid, classid) %>% summarise(class_n = n(schoolid))
cl %>% group_by(schoolid, classid) %>% summarise(class_n = count(schoolid))
cl %>% group_by(schoolid, classid)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(count(schoolid))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(n))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% arrange(cnt)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% arrange(desc(cnt))
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% mean
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% mean
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% summarise(mean)
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt) %>% summarise(mean(cnt))
312 / 107
cl %>% group_by(schoolid, classid) %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% select(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n())
cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt)
hist(cl %>% distinct(schoolid, classid) %>% group_by(schoolid) %>% summarise(cnt = n()) %>% select(cnt))
# model fit
summary(lme5)
summary(lme5)
lme2$
lme2
attributes(lme2)
lme2$class
lme2
library(foreign)
library(lme4)
library(lmerTest)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 60),
tidy = TRUE, warning = FALSE)
# load data
cl <- read.dta("classroom.dta")
# convert IDs to factor
cols_factor <- c("classid", "schoolid", "childid")
cl[cols_factor] <- lapply(cl[cols_factor], factor)
# unconditional means model
lme1 <- lmer(mathgain ~ (1 | schoolid), data = cl)
# log likelihood
logLik(lme1)
summary(lme1)
lme2 <- lmer(mathgain ~ (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme2)
summary(lme2)
lme3 <- lmer(mathgain ~ mathkind + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme3)
# model fit
summary(lme3)
lme4 <- lmer(mathgain ~ mathkind + ses + (1 | schoolid / classid), data = cl)
# log likelihood
logLik(lme4)
# model fit
summary(lme4)
# add variables
ses_sch <- cl %>% group_by(schoolid) %>% summarise(ses_sch = mean(ses))
ses_cls <- cl %>% group_by(schoolid, classid) %>% summarise(ses_cls = mean(ses))
mk_sch <- cl %>% group_by(schoolid) %>% summarise(mk_sch = mean(mathkind))
mk_cls <- cl %>%
group_by(schoolid, classid) %>%
summarise(mk_cls = mean(mathkind))
# add columns to main data
cl_new <- cl %>%
inner_join(ses_sch) %>%
inner_join(ses_cls) %>%
inner_join(mk_sch) %>%
inner_join(mk_cls)
# run model
lme5 <- lmer(mathgain ~ mathkind + ses + ses_sch + ses_cls + mk_sch + mk_cls +
(1 | schoolid / classid), data = cl_new)
# log likelihood
logLik(lme5)
# log likelihood
logLik(lme5)
# model fit
summary(lme5)
# not run
setwd("C:/Users/apagta950/Documents/NYU/Courses/Spring 2021/MDML/Final Project/US-News-NLP/scripts")
library(httr)
library(jsonlite)
library(lubridate)
library(rvest)
library(tidyverse)
library(tidytext)
# note: generate your own GNews API token and save it as a file called "api_token"
token <- colnames(read.csv("api_token"))
# parameters
topic <- "\"COVID-19\""
country <- "us"
language <- "en"
# article limit per API call under the free plan
limit <- "20"
source_c <- "cnn"
source_r <- "reuters"
source_f <- "fox"
getwd()
# note: generate your own GNews API token and save it as a file called "api_token"
token <- colnames(read.csv("../api_token"))
# note: generate your own GNews API token and save it as a file called "api_token"
token <- colnames(read.csv("../../api_token"))
# note: generate your own GNews API token and save it as a file called "api_token"
token <- colnames(read.csv("../../api_token"))
# note: generate your own GNews API token and save it as a file called "api_token"
token <- colnames(read.csv("../api_token"))
# note: generate your own GNews API token and save it as a file called "api_token"
token <- colnames(read.csv(".././api_token"))
# note: generate your own GNews API token and save it as a file called "api_token"
token <- colnames(read.csv("../api_token"))
token
topic <- "\"COVID-19\""
country <- "us"
language <- "en"
# article limit per API call under the free plan
limit <- "20"
source_c <- "cnn"
source_r <- "reuters"
source_f <- "fox"
# date range
date_init <- as.Date("2020-01-01")
date_end <- as.Date("2021-04-09")
date_init
date_end <- as.Date("2021-04-01")
get_date_range <- function(date_start, date_end, start_end = "start") {
# get start or end of week for each date, given range of dates
# date_start: beginning date
# date_end: end date
# start_end: Get first or last date of the week. Values: "start" or "end"
dates <- integer(0)
class(dates) <- "Date"
i <- 1
while (date_start <= date_end) {
if (start_end == "start")
{dates[i] <- floor_date(date_start, unit = "week")}
else
{dates[i] <- ceiling_date(date_start, unit = "week") - 1}
date_start <- date_start + 7
i <- i + 1
}
return(dates)
}
# date ranges for API
dates_start <- get_date_range(date_init, date_end, start_end = "start")
dates_end <- get_date_range(date_init, date_end, start_end = "end")
dates_start
dates_end
date_end <- as.Date("2020-04-01")
# date ranges for API
dates_start <- get_date_range(date_init, date_end, start_end = "start")
dates_end <- get_date_range(date_init, date_end, start_end = "end")
dates_start
dates_end
date_end <- as.Date("2020-01-01")
# date ranges for API
dates_start <- get_date_range(date_init, date_end, start_end = "start")
dates_end <- get_date_range(date_init, date_end, start_end = "end")
dates_start
dates_end
get_news <- function(topic, country, language, date_from,
date_to, source, limit, token) {
# get GNews API response
response <- GET(paste0("https://gnewsapi.net/api/search",
"?q=", URLencode(topic),
"&country=", country,
"&language=", language,
"&from=", date_from,
"&to=", date_to,
"&inurl=", source,
"&limit=", limit,
"&api_token=", token),
type = "basic")
return(response)
}
get_api_data <- function(topic, country, language, dates_start,
dates_end, source, limit, token) {
# API call - one call per week
# check API page in https://gnewsapi.net/settings#/api to monitor progress
api_results <- list()
for (i in seq_along(dates_start)) {
api_results[[i]] <- get_news(topic, country, language,
dates_start[i], dates_end[i],
source, limit, token)
}
# only include API results that return a valid status code
api_status_codes <- which(sapply(api_results, function(x) x$status_code) == 200)
# convert to dataframe
news <- bind_rows(
lapply(
api_results[api_status_codes], function(x) {
as.data.frame(fromJSON(content(x, "text"), flatten = TRUE))
}
)
)
return(news)
}
# Reuters API dataframe
news_fox <- get_api_data(topic, country, language, dates_start,
dates_end, source = source_f, limit, token)
news_fox
source_f <- "foxnews"
# Reuters API dataframe
news_fox <- get_api_data(topic, country, language, dates_start,
dates_end, source = source_f, limit, token)
fox_news
news_fox
news_fox$articles.article_url
article_url <- "https://www.foxnews.com/opinion/andrew-yang-universal-basic-income-welfare-steve-levy"
article_url
read_html(url) %>%
xml_find_all(
"//p[contains(@class, 'speakable')]"
) %>%
html_text(trim = TRUE)
read_html(url) %>%
xml_find_all(
"//p[contains(@class, 'speakable')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//p[contains(@class, 'speakable')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
# xml_find_all(
#   "//p[contains(@class, 'speakable')]"
# ) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//div[contains(@class, 'text')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//p[contains(@script, 'text/javascript')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//div[contains(@script, 'text/javascript')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//script[contains(@type, 'text/javascript')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//script[contains(@type, 'text/javascript')]"
) %>%
html_text(trim = TRUE)
class(read_html(article_url) %>%
xml_find_all(
"//script[contains(@type, 'text/javascript')]"
) %>%
html_text(trim = TRUE))
read_html(article_url) %>%
xml_find_all(
"//script[contains(@type, 'text/javascript')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//script[contains(@type, 'text/javascript')]"
)
read_html(article_url) %>%
xml_find_all(
"//p"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//p[contains(@p)]"
read_html(article_url) %>%
xml_find_all(
"//p[contains(@p)]"
)
read_html(article_url) %>%
xml_find_all(
"//p[contains(@p, 'p')]"
)
read_html(article_url) %>%
xml_find_all(
"//p"
) %>%
html_text(trim = TRUE)
class(read_html(article_url) %>%
xml_find_all(
"//p"
) %>%
html_text(trim = TRUE))
read_html(article_url) %>%
xml_find_all(
"//p[contains(@p, '')"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//p[contains(@p, '')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"//p[contains(@class, 'speakable')]"
) %>%
html_text(trim = TRUE)
read_html(article_url) %>%
xml_find_all(
"///p[contains(@p, '')]"
) %>%
html_text(trim = TRUE)
