words <- df %>%
unnest_tokens(word, text) %>%
left_join(get_sentiments(lexicon = "bing") %>%
mutate(sentiment_bing = sentiment) %>%
select(-sentiment)) %>%
left_join(get_sentiments(lexicon = "afinn") %>%
mutate(sentiment_afinn = as.factor(value)) %>%
select(-value)) %>%
left_join(get_sentiments(lexicon = "loughran") %>%
mutate(sentiment_loughran = sentiment) %>%
select(-sentiment)) %>%
left_join(get_sentiments(lexicon = "nrc") %>%
mutate(sentiment_nrc = sentiment) %>%
select(-sentiment))
return(words)
}
# baseline: tokenize words
words <- tokenize_words(articles)
# re-shape for plotting
words_long <- words %>%
pivot_longer(cols = contains("sentiment"),
names_to = "lexicon",
values_to = "sentiment")
# plot
words_long %>% filter(articles.source_name )
drop_na() %>%
ggplot(aes(x = sentiment, fill = articles.source_name)) +
geom_histogram(stat = "count", position = "dodge") +
facet_wrap(~lexicon, scales = "free") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# plot
words_long %>%
drop_na() %>%
ggplot(aes(x = sentiment, fill = articles.source_name)) +
geom_histogram(stat = "count", position = "dodge") +
facet_wrap(~lexicon, scales = "free") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
words_long
words_long %>% select(word, sentiment, lexicon)
words_long %>% select(word, sentiment, lexicon) %>% drop_na()
words_long %>% select(word, sentiment, lexicon) %>% drop_na() %>% group_by(word) %>% summarise(count = n()) %>% arrange(desc(count))
# top 100 words
words_long %>% select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
print(n = 100)
# top 20 words
words_long %>% select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20)
# top 20 words
words_long %>%
select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = word, y = count)) %>% geom_bar(stat = "identity")
# top 20 words
words_long %>%
select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = word, y = count)) +
geom_bar(stat = "identity")
# top 20 words
words_long %>%
select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity")
ords_long %>%
select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word, source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
words_long %>%
select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word, source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20)
colnames(words_long)
words_long$articles.source_domain
unique(words_long$articles.source_domain)
words_long %>% group_by(articles.source_domain) %>% summarise(n())
words_long %>% group_by(articles.source_domain, articles.source_name) %>% summarise(n())
articles %>% grouo_by(articles.source_domain, articles.source_name) %>% summarise(n())
articles %>% group_by(articles.source_domain, articles.source_name) %>% summarise(n())
articles %>% group_by(articles.source_domain, articles.source_name) %>% summarise(n()) %>% arrange(desc(n()))
articles %>% group_by(articles.source_domain, articles.source_name) %>% summarise(count = n()) %>% arrange(desc(count))
# read cnn and reuters. Drop International Reuters news sources
articles <- bind_rows(read_csv("../data/news_data_cnn.csv"),
read_csv("../data/news_data_reuters.csv") %>%
filter(articles.source_domain == "www.reuters.com"))
dim(articles)
# number of articles by source
articles %>%
group_by(articles.source_domain, articles.source_name) %>%
summarise(count())
# number of articles by source
articles %>%
group_by(articles.source_domain, articles.source_name) %>%
summarise(articles = n())
# number of articles by source
articles %>%
group_by(articles.source_domain, articles.source_name) %>%
summarise(articles = n()) %>%
arrange(desc(articles))
articles %>% filter(articles.source_name == "Reuters.com") %>% select(articles.article_url)
articles %>% filter(articles.source_name == "Reuters.com") %>% select(articles.article_url)
# read cnn and reuters. Drop International Reuters news sources
articles <- bind_rows(read_csv("../data/news_data_cnn.csv"),
read_csv("../data/news_data_reuters.csv") %>%
filter(
(articles.source_domain == "www.reuters.com") &
(articles.source_name == "Reuters"))
)
dim(articles)
articles %>%
group_by(articles.source_domain, articles.source_name) %>%
summarise(articles = n()) %>%
arrange(desc(articles))
articles %>% filter(articles.source_name == "amp.cnn.com") %>% select(articles.article_url)
articles %>% filter(articles.source_domain == "amp.cnn.com") %>% select(articles.article_url)
# number of articles by source
articles %>%
group_by(articles.source_domain, articles.source_name) %>%
summarise(articles = n()) %>%
arrange(desc(articles))
# baseline: tokenize words
words <- tokenize_words(articles)
dim(words)
words %>% select(articles.source_name) %>% distinct()
# words per article
words %>% group_by(articles.source_name) %>% summarise(count = n())
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(count = n())
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(count = n()) %>% arrange(desc(count))
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count,
y = word_count,
fill = articles.source_name)) %>%
geom_bar(position = "dodge")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count,
y = word_count,
fill = articles.source_name)) +
geom_bar(position = "dodge")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count,
y = word_count,
fill = articles.source_name)) +
geom_bar(stat = "identity", position = "dodge")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_hist(stat = "identity", position = "dodge")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_hist(position = "dodge")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_hist(position = "dodge")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_histogram(position = "dodge")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_histogram(position = "dodge") +
labs(title = "Word Count Distribution")
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>% arrange(desc(word_count))
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>% arrange(desc(word_count)) %>% selt(articles.article_url)
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>% arrange(desc(word_count)) %>% select(articles.article_url)
# re-shape for plotting
words_long <- words %>%
pivot_longer(cols = contains("sentiment"),
names_to = "lexicon",
values_to = "sentiment")
# plot
words_long %>%
drop_na() %>%
ggplot(aes(x = sentiment, fill = articles.source_name)) +
geom_histogram(stat = "count", position = "dodge") +
facet_wrap(~lexicon, scales = "free") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# number of articles by source
articles %>%
group_by(articles.source_domain, articles.source_name) %>%
summarise(articles = n()) %>%
arrange(desc(articles))
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_histogram(position = "dodge") +
labs(title = "Word Count Distribution")
# top 20 words
words_long %>%
select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word, articles.) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
ls()
# top 20 words
words_long %>%
select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word, articles.) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
words_long %>%
select(word, sentiment, lexicon) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20)
colnames(words_long)
# top 20 words
words_long %>%
select(word, sentiment, lexicon, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
words_long %>%
select(word, sentiment, lexicon, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20)
# top 20 words
words_long %>%
select(word, sentiment, lexicon, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# top 20 words
words %>%
select(word, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# top 20 words
words %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
colnames(words)
# top 20 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# top 20 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count), y = count)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20)
# top 20 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count),
y = count,
fill = articles.source_name)) +
geom_bar(stat = "identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# top 20 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(20) %>%
ggplot(aes(x = reorder(word, -count),
y = count,
fill = articles.source_name)) +
geom_bar(stat = "identity", position = "dodge") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# top 30 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(30) %>%
ggplot(aes(x = reorder(word, -count),
y = count,
fill = articles.source_name)) +
geom_bar(stat = "identity", position = "dodge") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# top 30 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(30) %>%
ggplot(aes(x = reorder(word, -count),
y = count,
fill = articles.source_name)) +
geom_bar(stat = "identity", position = "dodge") +
coord_flip() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# top 30 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(30) %>%
ggplot(aes(x = reorder(word, count),
y = count,
fill = articles.source_name)) +
geom_bar(stat = "identity", position = "dodge") +
coord_flip() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Word Sentiment")
# top 30 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(30) %>%
ggplot(aes(x = reorder(word, count),
y = count,
fill = articles.source_name)) +
geom_bar(stat = "identity", position = "dodge") +
coord_flip() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Top 30 Words")
y = count) +
# top 30 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(30) %>%
ggplot(aes(x = reorder(word, count),
y = count)) +
geom_bar(stat = "identity", position = "dodge") +
coord_flip() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Top 30 Words")
# top 30 words
words_long %>%
select(word, sentiment, articles.source_name) %>%
drop_na() %>%
group_by(word, articles.source_name) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(30) %>%
ggplot(aes(x = reorder(word, count), y = count)) +
geom_bar(stat = "identity", position = "dodge") +
coord_flip() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Top 30 Words (with a sentiment)")
# words per article
words_long %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_histogram(position = "dodge") +
labs(title = "Word Count Distribution")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_histogram(position = "dodge") +
labs(title = "Word Count Distribution")
# words per article
words %>%
group_by(articles.source_name, articles.article_url) %>%
summarise(word_count = n()) %>%
ggplot(aes(x = word_count, fill = articles.source_name)) +
geom_histogram(position = "dodge") +
labs(title = "Word Count Distribution")
dim(words)
dm(words_long)
dim(words_long)
dim(words_long %>% drop_na)
dim(words_long %>% drop_na %>% select(word) %>% distinct)
